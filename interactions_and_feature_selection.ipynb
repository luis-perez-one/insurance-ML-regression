{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lperez/.local/lib/python3.9/site-packages/pandas/compat/__init__.py:97: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression, LassoCV\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import regression_utils as mlu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simplifying the model\n",
    "From the EDA phase we concluded that both `region` and `children` are hardly relevant predictors. Therefore we migh just drop it from our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "csvFilePath = './datasets_13720_18513_insurance.csv'\n",
    "with open (csvFilePath, 'rb') as file:\n",
    "    data = pd.read_csv(file, encoding = 'UTF-8',\n",
    "                                    thousands = ',',\n",
    "                                    decimal = '.',\n",
    "                                    dtype = {\n",
    "                                            'sex':'category',\n",
    "                                            'smoker':'category',\n",
    "                                            'region':'category',\n",
    "                                            'children':'category',\n",
    "                                            }\n",
    "                                )\n",
    "\n",
    "cols_to_drop = ['region', 'children']\n",
    "data = data.drop(cols_to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>smoker</th>\n",
       "      <th>charges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>female</td>\n",
       "      <td>27.900</td>\n",
       "      <td>yes</td>\n",
       "      <td>16884.92400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>male</td>\n",
       "      <td>33.770</td>\n",
       "      <td>no</td>\n",
       "      <td>1725.55230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>male</td>\n",
       "      <td>33.000</td>\n",
       "      <td>no</td>\n",
       "      <td>4449.46200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>male</td>\n",
       "      <td>22.705</td>\n",
       "      <td>no</td>\n",
       "      <td>21984.47061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>male</td>\n",
       "      <td>28.880</td>\n",
       "      <td>no</td>\n",
       "      <td>3866.85520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age     sex     bmi smoker      charges\n",
       "0   19  female  27.900    yes  16884.92400\n",
       "1   18    male  33.770     no   1725.55230\n",
       "2   28    male  33.000     no   4449.46200\n",
       "3   33    male  22.705     no  21984.47061\n",
       "4   32    male  28.880     no   3866.85520"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## identify labels (aka. y, response_variable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_name = 'charges'\n",
    "y = np.array(data[y_name])\n",
    "data.drop(y_name, axis='columns', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## codify categorical features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex_female</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>smoker_no</th>\n",
       "      <th>smoker_yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1333</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1334</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1335</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1336</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1337</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1338 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      sex_female  sex_male  smoker_no  smoker_yes\n",
       "0              1         0          0           1\n",
       "1              0         1          1           0\n",
       "2              0         1          1           0\n",
       "3              0         1          1           0\n",
       "4              0         1          1           0\n",
       "...          ...       ...        ...         ...\n",
       "1333           0         1          1           0\n",
       "1334           1         0          1           0\n",
       "1335           1         0          1           0\n",
       "1336           1         0          1           0\n",
       "1337           1         0          0           1\n",
       "\n",
       "[1338 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummies_names = mlu.gen_dummy_col_names(data)\n",
    "dummies_inner_combinations = mlu.gen_dummy_cols_inner_combinations(dummies_names)\n",
    "#dummies_names and dummies_inner_combinations will be used later on\n",
    "\n",
    "X_cat = mlu.slice_categorical_features(data, y_name)\n",
    "data.drop(X_cat.columns, axis='columns', inplace=True)\n",
    "X_cat = pd.get_dummies(X_cat)\n",
    "X_cat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## standarize numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_num = mlu.get_numerical_features(data, y_name)\n",
    "X_num_names = X_num['names']\n",
    "data.drop(X_num_names, axis='columns', inplace=True)\n",
    "X_num = X_num['array']\n",
    "scaler = StandardScaler()\n",
    "X_num = scaler.fit_transform(X_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-1.43876426, -0.45332   ],\n",
       "        [-1.50996545,  0.5096211 ],\n",
       "        [-0.79795355,  0.38330685],\n",
       "        ...,\n",
       "        [-1.50996545,  1.0148781 ],\n",
       "        [-1.29636188, -0.79781341],\n",
       "        [ 1.55168573, -0.26138796]]),\n",
       " Index(['age', 'bmi'], dtype='object'))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_num, X_num_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1333</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1334</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1335</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1336</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1337</th>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1338 rows Ã— 0 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, ...]\n",
       "\n",
       "[1338 rows x 0 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**HicÃ© hasta aquÃ­**, queda pendiente revisar el resto del cÃ³digo para que quede mÃ¡s limpio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Can only merge Series or DataFrame objects, a <class 'numpy.ndarray'> was passed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/62/_h_88vpj0m977kms4wkvm6l80000gn/T/ipykernel_21689/1614250477.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_cat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36mmerge\u001b[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0mvalidate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m ) -> \"DataFrame\":\n\u001b[0;32m---> 74\u001b[0;31m     op = _MergeOperation(\n\u001b[0m\u001b[1;32m     75\u001b[0m         \u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0mright\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, left, right, how, on, left_on, right_on, axis, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m    596\u001b[0m         \u001b[0mvalidate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m     ):\n\u001b[0;32m--> 598\u001b[0;31m         \u001b[0m_left\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_validate_operand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0m_right\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_validate_operand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleft\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morig_left\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_left\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m_validate_operand\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m   2146\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2147\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2148\u001b[0;31m         raise TypeError(\n\u001b[0m\u001b[1;32m   2149\u001b[0m             \u001b[0;34mf\"Can only merge Series or DataFrame objects, a {type(obj)} was passed\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2150\u001b[0m         )\n",
      "\u001b[0;31mTypeError\u001b[0m: Can only merge Series or DataFrame objects, a <class 'numpy.ndarray'> was passed"
     ]
    }
   ],
   "source": [
    "X = pd.merge(X_num, X_cat, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactions \n",
    "In the EDA phase, several interactions seemed to be relevant, we will for starters see how the model behave if we include up to 2nd grade interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interaction_degree = 4\n",
    "interaction = PolynomialFeatures(degree=interaction_degree, include_bias=False, interaction_only=False)\n",
    "X_interaction = interaction.fit_transform(X)\n",
    "X_interaction_names = interaction.get_feature_names(X_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ru.clean_interaction_features(X_interaction, X_interaction_names, categorical_names, dummies_inner_combinations, interaction_degree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_interaction = features['set']\n",
    "X_interaction_names = features['names']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(X_interaction, y, test_size=0.3)\n",
    "\n",
    "tt_sets = {'train_features':train_features, \n",
    "           'test_features':test_features,\n",
    "           'train_labels':train_labels,\n",
    "           'test_labels':test_labels}\n",
    "\n",
    "for t_set in tt_sets.items():\n",
    "    print (f'{t_set[0]} shape: {t_set[1].shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regularization = LassoCV()\n",
    "regularization.fit(train_features, train_labels)\n",
    "print(f'Best alpha using built-in LassoCV: {regularization.alpha_}')\n",
    "print(f'Best score using built-in LassoCV: {regularization.score(train_features, train_labels)}')\n",
    "coeficients = pd.Series(regularization.coef_, index=X_interaction_names)\n",
    "print(f'Lasso picked {sum(coeficients != 0)} terms and eliminated the remaining {sum(coeficients==0)} terms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefficients = coeficients[coeficients!=0]\n",
    "relevant_features = coefficients.index\n",
    "relevant_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropping irrelevant interactions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = ru.drop_features(train_features,\n",
    "                                  X_interaction_names,\n",
    "                                  relevant_features,\n",
    "                                  selection_objective='keep')\n",
    "\n",
    "test_features = ru.drop_features(train_features,\n",
    "                                  X_interaction_names,\n",
    "                                  relevant_features,\n",
    "                                  selection_objective='keep')\n",
    "\n",
    "train_features = pd.DataFrame(train_features['set'], columns=train_features['names'])\n",
    "test_features = pd.DataFrame(test_features['set'], columns=test_features['names'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = remove_irrevelant_features(train_features, X_interaction_names, coefficients.index)\n",
    "train_features_names = train_features['names']\n",
    "train_features = train_features['set']\n",
    "\n",
    "X_interaction_names = train_features_names\n",
    "\n",
    "test_features = remove_irrevelant_features(test_features, X_interaction_names, coefficients.index)\n",
    "test_features_names = test_features['names']\n",
    "test_features = test_features['set']\n",
    "\n",
    "### one function for both sets, would delete 3 lines of this block!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression(fit_intercept = True)\n",
    "model.fit(train_features, train_labels)\n",
    "train_predictions = model.predict(train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_values = pd.DataFrame(model.coef_,\n",
    "                          X_interaction_names,\n",
    "                          columns=['coefficient'])\n",
    "\n",
    "beta_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## assesing performance - cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "folds = 30\n",
    "mse_crossfold = []\n",
    "mse_train_values = []\n",
    "mse_test_values = []\n",
    "for f in range (0, folds):\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    train_features, test_features, train_labels, test_labels = train_test_split(X_interaction, y, test_size=0.3)\n",
    "    train_predictions = model.predict(train_features)\n",
    "    train_errors = train_predictions - train_labels\n",
    "    mse_train = (train_errors**2).mean()\n",
    "    mse_train_values.append(mse_train)\n",
    "    mse_train = {'type':'train','mse':mse_train}\n",
    "    mse_crossfold.append(mse_train)\n",
    "    test_predictions = model.predict(test_features)\n",
    "    test_errors = test_predictions - test_labels\n",
    "    mse_test = (test_errors**2).mean()\n",
    "    mse_test_values.append(mse_test)\n",
    "    mse_test = {'type':'test','mse':mse_test}\n",
    "    mse_crossfold.append(mse_test)\n",
    "    \n",
    "mse_crossfold = pd.DataFrame(mse_crossfold)\n",
    "\n",
    "pfig0 = px.box(mse_crossfold, x='type', y='mse',\n",
    "                title='Crossfold validation, Mean Squared Error (MSE)',\n",
    "                color_discrete_sequence = px.colors.qualitative.D3\n",
    "            )\n",
    "pfig0.show()\n",
    "\n",
    "print(f'Train MSE mean fold values: {np.array(mse_train_values).mean()}')\n",
    "print(f'Test MSE mean fold values: {np.array(mse_test_values).mean()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both train and test MSE fold values show little skewness and quite similar medians. As expected, the test MSE fold values show a larger dispersion do to the fact that these sets have less values and therefore larger magnitude square errorrs are harder to compensate when calculating the mean.\n",
    "\n",
    "From the above statement we could say that the crossfold validation was successful, but if we really want to be obnoxious about it, since we would be dealing with the mean of means and we have a large enough (n=100) set of observations, we could appeal to the central limit theorem (the mean of means follow a normal distribution) and perform a two sided hypothesis testing to show that the means of the MSE crossfold values aren't statistically different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "displot = plt.figure(figsize=(12.8,8.16))\n",
    "title = f'distribution of MSE: crossfold validation'\n",
    "fig = sns.displot(data=mse_crossfold, x='mse', hue='type', kind='kde', palette='muted')\n",
    "fig.set(title=title)\n",
    "file_name = title + ' ' + datetime.now().isoformat()[:19]\n",
    "fig.savefig(file_name, bbox_inches='tight')\n",
    "plt.figure()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aspin-Welch Unequal-Variance T-Test\n",
    "[reference](https://ncss-wpengine.netdna-ssl.com/wp-content/themes/ncss/pdf/Procedures/NCSS/Two-Sample_T-Test_from_Means_and_SDs.pdf)\n",
    "\n",
    "- null: mean of the MSE of train and test are the same\n",
    "- alternate : mean of the MSE of train and test are different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aspin_welch_result = stats.ttest_ind(mse_train_values, mse_test_values, axis=0, equal_var=False, nan_policy='omit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aspin_welch_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a significance level of alpha=0.05, since this is a 2 sided test, the observed pvalue should be either lower than 0.025 or higher than 0.975 to reject the null hypothesis, with an observed pvalue of 0.5935 there is no staistical evidence to reject it. In other words, there is no evidence to make us think that the means of MSE fold values of the trainning and testing sets are different."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inferential statistics assumptions\n",
    "1. **Linearity**: It is assumed that the relationship between each predictor variable and the criterion variable is linear. \n",
    "    If this assumption is not met, then the predictions may systematically overestimate the actual values for one range of values on a predictor variable and underestimate them for another (bias).\n",
    "    \n",
    "    While working with high-dimensional data, it may not be practical to plot every dimension vs the prediction. An alternative is to use a prediction error plot, as it lets visualize how well the model does compared to the truth.\n",
    "\n",
    "\n",
    "2. **Residuals are normaly distributed**. The residuals (aka. erros) are the difference between predictions and the real values of the labels found in the data set.\n",
    "\n",
    "\n",
    "\n",
    "3. **Homoscedasticity**: Variances of the residuals are the same for all predicted values.\n",
    "\n",
    "Even though moderate violations of Assumptions 1 to 3 do not present a serious threat for the significance of predictor variables, even small transgressions to them could compromise the validity on certain predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_interaction = pd.DataFrame(X_interaction, columns=X_interaction_names)\n",
    "y = pd.DataFrame(data[y_name])\n",
    "data = pd.merge(y, X_interaction, left_index=True, right_index=True)\n",
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standarize_arr(_array):\n",
    "    _arr_mean = _array.mean()\n",
    "    _arr_stdev = _array.std()\n",
    "    _normalized_arr = (_array - _arr_mean)/_arr_stdev\n",
    "    return _normalized_arr\n",
    "\n",
    "def create_error_analysis_df(_data, _y_name, _train_labels, _train_predictions, _test_labels, _test_predictions):\n",
    "    _error_analysis_df_train = pd.DataFrame()\n",
    "    _error_analysis_df_train[_y_name] = _train_labels\n",
    "    _error_analysis_df_train['prediction'] = _train_predictions\n",
    "    _error_analysis_df_train['split'] = 'train'\n",
    "    \n",
    "    _error_analysis_df_test = pd.DataFrame()\n",
    "    _error_analysis_df_test[_y_name] = _test_labels\n",
    "    _error_analysis_df_test['prediction'] = _test_predictions\n",
    "    _error_analysis_df_test['split'] = 'test'\n",
    "    \n",
    "    _error_analysis_df = pd.concat([_error_analysis_df_train, _error_analysis_df_test], ignore_index=True)\n",
    "    _error_analysis_df['residual'] = _error_analysis_df['prediction'] -  _error_analysis_df[y_name]\n",
    "    _error_analysis_df['standarized_residual'] = standarize_arr(_error_analysis_df['residual'])\n",
    "    \n",
    "    _error_analysis_df['residual_theoretical_normal_P'] = stats.norm.cdf(_error_analysis_df['standarized_residual'])\n",
    "    _error_analysis_df['residual_observed_P'] = _error_analysis_df['residual'].rank(pct = True) \n",
    "          \n",
    "    return(_error_analysis_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_data = create_error_analysis_df(data, y_name, train_labels, train_predictions, test_labels, \n",
    "test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "InteractiveShell.ast_node_interactivity = 'last'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1 = px.scatter(error_data,\n",
    "                 x = y_name,\n",
    "                 y = 'prediction',\n",
    "                 marginal_x = 'histogram',\n",
    "                 marginal_y = 'histogram',\n",
    "                 color = 'split',\n",
    "                 title = 'Linearity: Prediction error plot',\n",
    "                 color_discrete_sequence = px.colors.qualitative.D3\n",
    "               )\n",
    "\n",
    "fig1.update_traces(histnorm='probability', selector={'type':'histogram'})\n",
    "\n",
    "fig1.add_shape(type = 'line',\n",
    "              line = {'dash' : 'dash'},\n",
    "              x0 = y.min(), y0=y.min(),\n",
    "              x1 = y.max(), y1=y.max()\n",
    "              )\n",
    "\n",
    "fig1.update_layout(xaxis = {'scaleanchor':'y', 'scaleratio':1, 'ticks':'outside'},\n",
    "                   yaxis = {'ticks':'outside'},\n",
    "                   autosize = False,\n",
    "                   width = 500,\n",
    "                   height = 500,\n",
    "                   dragmode = False\n",
    "                  )\n",
    "fig1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig2 = px.scatter(error_data,\n",
    "                 x = error_data['residual_theoretical_normal_P'],\n",
    "                 y = error_data['residual_observed_P']     ,\n",
    "                 color_discrete_sequence = px.colors.qualitative.D3          \n",
    "               )\n",
    "\n",
    "fig2.add_shape(type = 'line',\n",
    "              line = {'dash' : 'dash'},\n",
    "              x0 = 0, y0 = 0,\n",
    "              x1 = 1, y1 = 1\n",
    "              )\n",
    "\n",
    "fig2.update_layout(xaxis = {'scaleanchor':'y', 'scaleratio':1, 'ticks':'outside'},\n",
    "                   yaxis = {'ticks':'outside'},\n",
    "                   autosize = False,\n",
    "                   width = 500,\n",
    "                   height = 500,\n",
    "                   dragmode = False\n",
    "                  )\n",
    "fig2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig3 = px.scatter(error_data,\n",
    "                 x = 'prediction',\n",
    "                 y = 'standarized_residual',\n",
    "                 color = 'split',\n",
    "                 title = 'Residuals Homoscedasticity',\n",
    "                 color_discrete_sequence = px.colors.qualitative.D3\n",
    "               )\n",
    "\n",
    "fig3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
