{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lperez/.local/lib/python3.9/site-packages/pandas/compat/__init__.py:97: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression, LassoCV\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from datetime import datetime\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simplifying the model\n",
    "From the EDA phase we concluded that both `region` and `children` are hardly relevant predictors. Therefore we migh just drop it from our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "csvFilePath = './datasets_13720_18513_insurance.csv'\n",
    "with open (csvFilePath, 'rb') as file:\n",
    "    data = pd.read_csv(file, encoding = 'UTF-8',\n",
    "                                    thousands = ',',\n",
    "                                    decimal = '.',\n",
    "                                    dtype = {\n",
    "                                            'sex':'category',\n",
    "                                            'smoker':'category',\n",
    "                                            'region':'category',\n",
    "                                            'children':'category',\n",
    "                                            }\n",
    "                                )\n",
    "\n",
    "cols_to_drop = ['region', 'children']\n",
    "data = data.drop(cols_to_drop, axis=1)\n",
    "\n",
    "\n",
    "\n",
    "def gen_dummy_col_names(dataframe):\n",
    "    category_dataframe = dataframe.select_dtypes(include='category')\n",
    "    dummy_col_names = []\n",
    "    for c in category_dataframe.columns:\n",
    "        unique_col_vals = category_dataframe[c].unique().tolist()\n",
    "        dummy_col_names.append([c + '_' + val for val in unique_col_vals])\n",
    "    \n",
    "    return dummy_col_names\n",
    "\n",
    "def gen_dummy_cols_inner_combinations(dummy_col_names):\n",
    "    #dummy_col_names should be a list of lists, ie\n",
    "    #[['sex_female', 'sex_male'], ['smoker_yes', 'smoker_no']]\n",
    "    dummy_cols_inner_combinations = []\n",
    "    for col_list in dummy_col_names:\n",
    "        col_list.sort()\n",
    "        list_lenght = len(col_list)\n",
    "        if list_lenght > 1:\n",
    "            for lenght in range(2, list_lenght+1):\n",
    "                for subset in itertools.combinations(col_list, lenght):\n",
    "                    dummy_cols_inner_combinations.append(subset)\n",
    "    \n",
    "    dummy_cols_inner_combinations = [list(element) for element in dummy_cols_inner_combinations]\n",
    "    dummy_cols_inner_combinations = [' '.join(element) for element in dummy_cols_inner_combinations]\n",
    "      \n",
    "    return(dummy_cols_inner_combinations)\n",
    "\n",
    "\n",
    "dummies_names = gen_dummy_col_names(data)\n",
    "dummies_inner_combinations = gen_dummy_cols_inner_combinations(dummies_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to encode our categorical predictors, in this case `sex` and `smoker`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>bmi</th>\n",
       "      <th>charges</th>\n",
       "      <th>sex_female</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>smoker_no</th>\n",
       "      <th>smoker_yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>27.900</td>\n",
       "      <td>16884.92400</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>33.770</td>\n",
       "      <td>1725.55230</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>33.000</td>\n",
       "      <td>4449.46200</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>22.705</td>\n",
       "      <td>21984.47061</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>28.880</td>\n",
       "      <td>3866.85520</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age     bmi      charges  sex_female  sex_male  smoker_no  smoker_yes\n",
       "0   19  27.900  16884.92400           1         0          0           1\n",
       "1   18  33.770   1725.55230           0         1          1           0\n",
       "2   28  33.000   4449.46200           0         1          1           0\n",
       "3   33  22.705  21984.47061           0         1          1           0\n",
       "4   32  28.880   3866.85520           0         1          1           0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.get_dummies(data)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split labels (y) and features (X) into numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>bmi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>27.900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>33.770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>33.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>22.705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>28.880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1333</th>\n",
       "      <td>50</td>\n",
       "      <td>30.970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1334</th>\n",
       "      <td>18</td>\n",
       "      <td>31.920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1335</th>\n",
       "      <td>18</td>\n",
       "      <td>36.850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1336</th>\n",
       "      <td>21</td>\n",
       "      <td>25.800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1337</th>\n",
       "      <td>61</td>\n",
       "      <td>29.070</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1338 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age     bmi\n",
       "0      19  27.900\n",
       "1      18  33.770\n",
       "2      28  33.000\n",
       "3      33  22.705\n",
       "4      32  28.880\n",
       "...   ...     ...\n",
       "1333   50  30.970\n",
       "1334   18  31.920\n",
       "1335   18  36.850\n",
       "1336   21  25.800\n",
       "1337   61  29.070\n",
       "\n",
       "[1338 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_name = 'charges'\n",
    "y = np.array(data[y_name])\n",
    "\n",
    "X = data.drop(y_name, axis=1)\n",
    "X_names = list(X.columns)\n",
    "numeric_features = ['age', 'bmi']\n",
    "\n",
    "X_numeric = X[numeric_features]\n",
    "X_numeric\n",
    "X_numeric = np.array(X_numeric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standarize the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>bmi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.438764</td>\n",
       "      <td>-0.453320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.509965</td>\n",
       "      <td>0.509621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.797954</td>\n",
       "      <td>0.383307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.441948</td>\n",
       "      <td>-1.305531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.513149</td>\n",
       "      <td>-0.292556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1333</th>\n",
       "      <td>0.768473</td>\n",
       "      <td>0.050297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1334</th>\n",
       "      <td>-1.509965</td>\n",
       "      <td>0.206139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1335</th>\n",
       "      <td>-1.509965</td>\n",
       "      <td>1.014878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1336</th>\n",
       "      <td>-1.296362</td>\n",
       "      <td>-0.797813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1337</th>\n",
       "      <td>1.551686</td>\n",
       "      <td>-0.261388</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1338 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           age       bmi\n",
       "0    -1.438764 -0.453320\n",
       "1    -1.509965  0.509621\n",
       "2    -0.797954  0.383307\n",
       "3    -0.441948 -1.305531\n",
       "4    -0.513149 -0.292556\n",
       "...        ...       ...\n",
       "1333  0.768473  0.050297\n",
       "1334 -1.509965  0.206139\n",
       "1335 -1.509965  1.014878\n",
       "1336 -1.296362 -0.797813\n",
       "1337  1.551686 -0.261388\n",
       "\n",
       "[1338 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X_numeric = scaler.fit_transform(X_numeric)\n",
    "X_numeric = pd.DataFrame(X_numeric, columns=numeric_features)\n",
    "X_numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = []\n",
    "for c in data.columns:\n",
    "    if (c not in numeric_features) & (c != y_name):\n",
    "        categorical_features.append(c)\n",
    "            \n",
    "X_categorical = data[categorical_features]\n",
    "categorical_names =  X_categorical.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.merge(X_numeric, X_categorical, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactions \n",
    "In the EDA phase, several interactions seemed to be relevant, we will for starters see how the model behave if we include up to 2nd grade interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "interaction_degree = 4\n",
    "interaction = PolynomialFeatures(degree=interaction_degree, include_bias=False, interaction_only=False)\n",
    "X_interaction = interaction.fit_transform(X)\n",
    "X_interaction_names = interaction.get_feature_names(X_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_features_array(features_array, features_names,\n",
    "                         categorical_features_names, dummies_inner_combinations,\n",
    "                         interaction_degree):\n",
    "    #this function remove non-sense terms like categorical terms n-powered\n",
    "    #ie. smoker_yes^2 and inner combinations of categorical terms ie.:\n",
    "    #(sex_female sex_male)\n",
    "    \n",
    "    # generate all expressions that if partially matched in feature names\n",
    "    # will get them dropped\n",
    "    non_sense_expressions = []\n",
    "    for c in categorical_features_names:\n",
    "        for degree in range (2, interaction_degree+1):\n",
    "            expression = c + '^' + str(degree)\n",
    "            non_sense_expressions.append(expression)\n",
    "            \n",
    "    non_sense_expressions.extend(dummies_inner_combinations)\n",
    "    \n",
    "    # generate a list of the columns to be dropped\n",
    "    features = pd.DataFrame(features_array, columns=features_names)\n",
    "    cols_to_drop = []\n",
    "    for c in features.columns:\n",
    "        for expression in non_sense_expressions:\n",
    "            if c.find(expression) != -1:\n",
    "                cols_to_drop.append(c)\n",
    "    cols_to_drop = set(cols_to_drop)\n",
    "    \n",
    "    features.drop(cols_to_drop, axis='columns', inplace=True)\n",
    "    \n",
    "    features = {'names':features.columns, 'set':np.array(features)}\n",
    "    \n",
    "    return features\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = clean_features_array(X_interaction, X_interaction_names, categorical_names, dummies_inner_combinations, interaction_degree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_interaction = features['set']\n",
    "X_interaction_names = features['names']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_features shape: (936, 78)\n",
      "test_features shape: (402, 78)\n",
      "train_labels shape: (936,)\n",
      "test_labels shape: (402,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(X_interaction, y, test_size=0.3)\n",
    "\n",
    "tt_sets = {'train_features':train_features, \n",
    "           'test_features':test_features,\n",
    "           'train_labels':train_labels,\n",
    "           'test_labels':test_labels}\n",
    "\n",
    "for t_set in tt_sets.items():\n",
    "    print (f'{t_set[0]} shape: {t_set[1].shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LassoCV()"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha using built-in LassoCV: 115.47590247368781\n",
      "Best score using built-in LassoCV: 0.8390357000878067\n",
      "Lasso picked 16 terms and eliminated the remaining 62 terms\n"
     ]
    }
   ],
   "source": [
    "regularization = LassoCV()\n",
    "regularization.fit(train_features, train_labels)\n",
    "print(f'Best alpha using built-in LassoCV: {regularization.alpha_}')\n",
    "print(f'Best score using built-in LassoCV: {regularization.score(train_features, train_labels)}')\n",
    "coeficients = pd.Series(regularization.coef_, index=X_interaction_names)\n",
    "print(f'Lasso picked {sum(coeficients != 0)} terms and eliminated the remaining {sum(coeficients==0)} terms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                           3.082015e+03\n",
       "bmi                           3.025186e+01\n",
       "smoker_no                    -2.328883e+04\n",
       "smoker_yes                    1.784118e-10\n",
       "age^2                         1.868424e+02\n",
       "bmi smoker_yes                9.873621e+03\n",
       "age^3                         1.730240e+02\n",
       "age^2 bmi                     1.105483e+02\n",
       "bmi^2 sex_male               -2.091472e+02\n",
       "bmi^2 smoker_no              -6.151825e+01\n",
       "age^3 bmi                     3.003643e+01\n",
       "age^3 sex_male                5.805136e+01\n",
       "age^2 sex_female smoker_no    8.823763e+01\n",
       "age bmi^2 sex_female          7.725934e+01\n",
       "bmi^3 sex_male               -5.780944e-01\n",
       "bmi^3 smoker_yes             -4.177776e+02\n",
       "dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coefficients = coeficients[coeficients!=0]\n",
    "coefficients\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropping irrelevant interactions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_irrevelant_features(feature_set, feature_set_column_names, features_to_keep_list):\n",
    "    feature_set = pd.DataFrame(feature_set, columns=feature_set_column_names)\n",
    "    cols_to_drop = []\n",
    "    for c in feature_set.columns:\n",
    "        if c not in features_to_keep_list:\n",
    "            cols_to_drop.append(c)\n",
    "    feature_set.drop(cols_to_drop, axis='columns', inplace=True)\n",
    "    feature_set_names = feature_set.columns\n",
    "    feature_set = np.array(feature_set)\n",
    "    features = {'names':feature_set_names, 'set':feature_set}\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Shape of passed values is (402, 78), indices imply (402, 16)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mcreate_block_manager_from_blocks\u001b[0;34m(blocks, axes)\u001b[0m\n\u001b[1;32m   1674\u001b[0m                 blocks = [\n\u001b[0;32m-> 1675\u001b[0;31m                     make_block(\n\u001b[0m\u001b[1;32m   1676\u001b[0m                         \u001b[0mvalues\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplacement\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36mmake_block\u001b[0;34m(values, placement, klass, ndim, dtype)\u001b[0m\n\u001b[1;32m   2741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2742\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mklass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplacement\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplacement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2743\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, values, placement, ndim)\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_ndim\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmgr_locs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    143\u001b[0m                 \u001b[0;34mf\"Wrong number of items passed {len(self.values)}, \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Wrong number of items passed 78, placement implies 16",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/62/_h_88vpj0m977kms4wkvm6l80000gn/T/ipykernel_21664/2676505843.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mX_interaction_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_features_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtest_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mremove_irrevelant_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_interaction_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoefficients\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mtest_features_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mtest_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'set'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/62/_h_88vpj0m977kms4wkvm6l80000gn/T/ipykernel_21664/2503934917.py\u001b[0m in \u001b[0;36mremove_irrevelant_features\u001b[0;34m(feature_set, feature_set_column_names, features_to_keep_list)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mremove_irrevelant_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_set_column_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures_to_keep_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mfeature_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature_set_column_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mcols_to_drop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeature_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeatures_to_keep_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    556\u001b[0m                 \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 558\u001b[0;31m                 \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_ndarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    559\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0;31m# For data is list-like, or Iterable (will consume into list)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36minit_ndarray\u001b[0;34m(values, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0mblock_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcreate_block_manager_from_blocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mcreate_block_manager_from_blocks\u001b[0;34m(blocks, axes)\u001b[0m\n\u001b[1;32m   1685\u001b[0m         \u001b[0mblocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"values\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mblocks\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1686\u001b[0m         \u001b[0mtot_items\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mblocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1687\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mconstruction_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtot_items\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblocks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Shape of passed values is (402, 78), indices imply (402, 16)"
     ]
    }
   ],
   "source": [
    "train_features = remove_irrevelant_features(train_features, X_interaction_names, coefficients.index)\n",
    "train_features_names = train_features['names']\n",
    "train_features = train_features['set']\n",
    "\n",
    "X_interaction_names = train_features_names\n",
    "\n",
    "test_features = remove_irrevelant_features(test_features, X_interaction_names, coefficients.index)\n",
    "test_features_names = test_features['names']\n",
    "test_features = test_features['set']\n",
    "\n",
    "### one function for both sets, would delete 3 lines of this block!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression(fit_intercept = True)\n",
    "model.fit(train_features, train_labels)\n",
    "train_predictions = model.predict(train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_values = pd.DataFrame(model.coef_,\n",
    "                          X_interaction_names,\n",
    "                          columns=['coefficient'])\n",
    "\n",
    "beta_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## assesing performance - cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "folds = 30\n",
    "mse_crossfold = []\n",
    "mse_train_values = []\n",
    "mse_test_values = []\n",
    "for f in range (0, folds):\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    train_features, test_features, train_labels, test_labels = train_test_split(X_interaction, y, test_size=0.3)\n",
    "    train_predictions = model.predict(train_features)\n",
    "    train_errors = train_predictions - train_labels\n",
    "    mse_train = (train_errors**2).mean()\n",
    "    mse_train_values.append(mse_train)\n",
    "    mse_train = {'type':'train','mse':mse_train}\n",
    "    mse_crossfold.append(mse_train)\n",
    "    test_predictions = model.predict(test_features)\n",
    "    test_errors = test_predictions - test_labels\n",
    "    mse_test = (test_errors**2).mean()\n",
    "    mse_test_values.append(mse_test)\n",
    "    mse_test = {'type':'test','mse':mse_test}\n",
    "    mse_crossfold.append(mse_test)\n",
    "    \n",
    "mse_crossfold = pd.DataFrame(mse_crossfold)\n",
    "\n",
    "pfig0 = px.box(mse_crossfold, x='type', y='mse',\n",
    "                title='Crossfold validation, Mean Squared Error (MSE)',\n",
    "                color_discrete_sequence = px.colors.qualitative.D3\n",
    "            )\n",
    "pfig0.show()\n",
    "\n",
    "print(f'Train MSE mean fold values: {np.array(mse_train_values).mean()}')\n",
    "print(f'Test MSE mean fold values: {np.array(mse_test_values).mean()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both train and test MSE fold values show little skewness and quite similar medians. As expected, the test MSE fold values show a larger dispersion do to the fact that these sets have less values and therefore larger magnitude square errorrs are harder to compensate when calculating the mean.\n",
    "\n",
    "From the above statement we could say that the crossfold validation was successful, but if we really want to be obnoxious about it, since we would be dealing with the mean of means and we have a large enough (n=100) set of observations, we could appeal to the central limit theorem (the mean of means follow a normal distribution) and perform a two sided hypothesis testing to show that the means of the MSE crossfold values aren't statistically different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "displot = plt.figure(figsize=(12.8,8.16))\n",
    "title = f'distribution of MSE: crossfold validation'\n",
    "fig = sns.displot(data=mse_crossfold, x='mse', hue='type', kind='kde', palette='muted')\n",
    "fig.set(title=title)\n",
    "file_name = title + ' ' + datetime.now().isoformat()[:19]\n",
    "fig.savefig(file_name, bbox_inches='tight')\n",
    "plt.figure()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aspin-Welch Unequal-Variance T-Test\n",
    "[reference](https://ncss-wpengine.netdna-ssl.com/wp-content/themes/ncss/pdf/Procedures/NCSS/Two-Sample_T-Test_from_Means_and_SDs.pdf)\n",
    "\n",
    "- null: mean of the MSE of train and test are the same\n",
    "- alternate : mean of the MSE of train and test are different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aspin_welch_result = stats.ttest_ind(mse_train_values, mse_test_values, axis=0, equal_var=False, nan_policy='omit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aspin_welch_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a significance level of alpha=0.05, since this is a 2 sided test, the observed pvalue should be either lower than 0.025 or higher than 0.975 to reject the null hypothesis, with an observed pvalue of 0.5935 there is no staistical evidence to reject it. In other words, there is no evidence to make us think that the means of MSE fold values of the trainning and testing sets are different."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inferential statistics assumptions\n",
    "1. **Linearity**: It is assumed that the relationship between each predictor variable and the criterion variable is linear. \n",
    "    If this assumption is not met, then the predictions may systematically overestimate the actual values for one range of values on a predictor variable and underestimate them for another (bias).\n",
    "    \n",
    "    While working with high-dimensional data, it may not be practical to plot every dimension vs the prediction. An alternative is to use a prediction error plot, as it lets visualize how well the model does compared to the truth.\n",
    "\n",
    "\n",
    "2. **Residuals are normaly distributed**. The residuals (aka. erros) are the difference between predictions and the real values of the labels found in the data set.\n",
    "\n",
    "\n",
    "\n",
    "3. **Homoscedasticity**: Variances of the residuals are the same for all predicted values.\n",
    "\n",
    "Even though moderate violations of Assumptions 1 to 3 do not present a serious threat for the significance of predictor variables, even small transgressions to them could compromise the validity on certain predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_interaction = pd.DataFrame(X_interaction, columns=X_interaction_names)\n",
    "y = pd.DataFrame(data[y_name])\n",
    "data = pd.merge(y, X_interaction, left_index=True, right_index=True)\n",
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standarize_arr(_array):\n",
    "    _arr_mean = _array.mean()\n",
    "    _arr_stdev = _array.std()\n",
    "    _normalized_arr = (_array - _arr_mean)/_arr_stdev\n",
    "    return _normalized_arr\n",
    "\n",
    "def create_error_analysis_df(_data, _y_name, _train_labels, _train_predictions, _test_labels, _test_predictions):\n",
    "    _error_analysis_df_train = pd.DataFrame()\n",
    "    _error_analysis_df_train[_y_name] = _train_labels\n",
    "    _error_analysis_df_train['prediction'] = _train_predictions\n",
    "    _error_analysis_df_train['split'] = 'train'\n",
    "    \n",
    "    _error_analysis_df_test = pd.DataFrame()\n",
    "    _error_analysis_df_test[_y_name] = _test_labels\n",
    "    _error_analysis_df_test['prediction'] = _test_predictions\n",
    "    _error_analysis_df_test['split'] = 'test'\n",
    "    \n",
    "    _error_analysis_df = pd.concat([_error_analysis_df_train, _error_analysis_df_test], ignore_index=True)\n",
    "    _error_analysis_df['residual'] = _error_analysis_df['prediction'] -  _error_analysis_df[y_name]\n",
    "    _error_analysis_df['standarized_residual'] = standarize_arr(_error_analysis_df['residual'])\n",
    "    \n",
    "    _error_analysis_df['residual_theoretical_normal_P'] = stats.norm.cdf(_error_analysis_df['standarized_residual'])\n",
    "    _error_analysis_df['residual_observed_P'] = _error_analysis_df['residual'].rank(pct = True) \n",
    "          \n",
    "    return(_error_analysis_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_data = create_error_analysis_df(data, y_name, train_labels, train_predictions, test_labels, \n",
    "test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "InteractiveShell.ast_node_interactivity = 'last'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1 = px.scatter(error_data,\n",
    "                 x = y_name,\n",
    "                 y = 'prediction',\n",
    "                 marginal_x = 'histogram',\n",
    "                 marginal_y = 'histogram',\n",
    "                 color = 'split',\n",
    "                 title = 'Linearity: Prediction error plot',\n",
    "                 color_discrete_sequence = px.colors.qualitative.D3\n",
    "               )\n",
    "\n",
    "fig1.update_traces(histnorm='probability', selector={'type':'histogram'})\n",
    "\n",
    "fig1.add_shape(type = 'line',\n",
    "              line = {'dash' : 'dash'},\n",
    "              x0 = y.min(), y0=y.min(),\n",
    "              x1 = y.max(), y1=y.max()\n",
    "              )\n",
    "\n",
    "fig1.update_layout(xaxis = {'scaleanchor':'y', 'scaleratio':1, 'ticks':'outside'},\n",
    "                   yaxis = {'ticks':'outside'},\n",
    "                   autosize = False,\n",
    "                   width = 500,\n",
    "                   height = 500,\n",
    "                   dragmode = False\n",
    "                  )\n",
    "fig1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig2 = px.scatter(error_data,\n",
    "                 x = error_data['residual_theoretical_normal_P'],\n",
    "                 y = error_data['residual_observed_P']     ,\n",
    "                 color_discrete_sequence = px.colors.qualitative.D3          \n",
    "               )\n",
    "\n",
    "fig2.add_shape(type = 'line',\n",
    "              line = {'dash' : 'dash'},\n",
    "              x0 = 0, y0 = 0,\n",
    "              x1 = 1, y1 = 1\n",
    "              )\n",
    "\n",
    "fig2.update_layout(xaxis = {'scaleanchor':'y', 'scaleratio':1, 'ticks':'outside'},\n",
    "                   yaxis = {'ticks':'outside'},\n",
    "                   autosize = False,\n",
    "                   width = 500,\n",
    "                   height = 500,\n",
    "                   dragmode = False\n",
    "                  )\n",
    "fig2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig3 = px.scatter(error_data,\n",
    "                 x = 'prediction',\n",
    "                 y = 'standarized_residual',\n",
    "                 color = 'split',\n",
    "                 title = 'Residuals Homoscedasticity',\n",
    "                 color_discrete_sequence = px.colors.qualitative.D3\n",
    "               )\n",
    "\n",
    "fig3.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
